{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy3 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "stopwords_ru = stopwords.words(\"russian\")\n",
    "\n",
    "def morphe(str):\n",
    "    return ' '.join([morph.normal_forms(w)[0] for w in str.split() if w not in stopwords_ru])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillna_columns = [\n",
    "    \"занятость\",\n",
    "    \"по должности-лемме\",\n",
    "    \"по дополнительному признаку\",\n",
    "    \"по условиям\",\n",
    "    \"общие фразы\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"answers.csv\", index_col='Unnamed: 0')\n",
    "for col in fillna_columns:\n",
    "    df.fillna({col: f'{col}_нет'}, inplace=True)\n",
    "\n",
    "df['query'] = df['query'].apply(morphe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_columns = ['по должности-лемме', 'по условиям', 'общие фразы']\n",
    "multilabel_columns = ['занятость', 'по дополнительному признаку']\n",
    "vectorizer_columns = 'query'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x):\n",
    "    return [i for i in set(x.split(',')) if len(i)>0]\n",
    "\n",
    "for col in multilabel_columns:\n",
    "    df[col] = df[col].apply(lambda x: split(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['query']]\n",
    "y = df.drop(columns=['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>занятость</th>\n",
       "      <th>по должности-лемме</th>\n",
       "      <th>по дополнительному признаку</th>\n",
       "      <th>по условиям</th>\n",
       "      <th>общие фразы</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[занятость_нет]</td>\n",
       "      <td>по должности-лемме_нет</td>\n",
       "      <td>[по дополнительному признаку_нет]</td>\n",
       "      <td>по условиям_нет</td>\n",
       "      <td>общая фраза</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[занятость_нет]</td>\n",
       "      <td>по должности-лемме_нет</td>\n",
       "      <td>[по дополнительному признаку_нет]</td>\n",
       "      <td>по условиям_нет</td>\n",
       "      <td>общая фраза</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[занятость_нет]</td>\n",
       "      <td>Рабочий</td>\n",
       "      <td>[по дополнительному признаку_нет]</td>\n",
       "      <td>по условиям_нет</td>\n",
       "      <td>общие фразы_нет</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[на неполный день]</td>\n",
       "      <td>Водитель</td>\n",
       "      <td>[по дополнительному признаку_нет]</td>\n",
       "      <td>по условиям_нет</td>\n",
       "      <td>общие фразы_нет</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[занятость_нет]</td>\n",
       "      <td>Водитель</td>\n",
       "      <td>[по дополнительному признаку_нет]</td>\n",
       "      <td>по условиям_нет</td>\n",
       "      <td>общие фразы_нет</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14240</th>\n",
       "      <td>[занятость_нет]</td>\n",
       "      <td>по должности-лемме_нет</td>\n",
       "      <td>[по дополнительному признаку_нет]</td>\n",
       "      <td>по условиям_нет</td>\n",
       "      <td>общая фраза</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14241</th>\n",
       "      <td>[занятость_нет]</td>\n",
       "      <td>по должности-лемме_нет</td>\n",
       "      <td>[по дополнительному признаку_нет]</td>\n",
       "      <td>по условиям_нет</td>\n",
       "      <td>общая фраза</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14242</th>\n",
       "      <td>[занятость_нет]</td>\n",
       "      <td>по должности-лемме_нет</td>\n",
       "      <td>[по дополнительному признаку_нет]</td>\n",
       "      <td>по условиям_нет</td>\n",
       "      <td>общая фраза</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14243</th>\n",
       "      <td>[занятость_нет]</td>\n",
       "      <td>по должности-лемме_нет</td>\n",
       "      <td>[по дополнительному признаку_нет]</td>\n",
       "      <td>по условиям_нет</td>\n",
       "      <td>общая фраза</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14244</th>\n",
       "      <td>[занятость_нет]</td>\n",
       "      <td>по должности-лемме_нет</td>\n",
       "      <td>[по дополнительному признаку_нет]</td>\n",
       "      <td>по условиям_нет</td>\n",
       "      <td>общая фраза</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14245 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                занятость      по должности-лемме  \\\n",
       "0         [занятость_нет]  по должности-лемме_нет   \n",
       "1         [занятость_нет]  по должности-лемме_нет   \n",
       "2         [занятость_нет]                 Рабочий   \n",
       "3      [на неполный день]                Водитель   \n",
       "4         [занятость_нет]                Водитель   \n",
       "...                   ...                     ...   \n",
       "14240     [занятость_нет]  по должности-лемме_нет   \n",
       "14241     [занятость_нет]  по должности-лемме_нет   \n",
       "14242     [занятость_нет]  по должности-лемме_нет   \n",
       "14243     [занятость_нет]  по должности-лемме_нет   \n",
       "14244     [занятость_нет]  по должности-лемме_нет   \n",
       "\n",
       "             по дополнительному признаку      по условиям      общие фразы  \n",
       "0      [по дополнительному признаку_нет]  по условиям_нет      общая фраза  \n",
       "1      [по дополнительному признаку_нет]  по условиям_нет      общая фраза  \n",
       "2      [по дополнительному признаку_нет]  по условиям_нет  общие фразы_нет  \n",
       "3      [по дополнительному признаку_нет]  по условиям_нет  общие фразы_нет  \n",
       "4      [по дополнительному признаку_нет]  по условиям_нет  общие фразы_нет  \n",
       "...                                  ...              ...              ...  \n",
       "14240  [по дополнительному признаку_нет]  по условиям_нет      общая фраза  \n",
       "14241  [по дополнительному признаку_нет]  по условиям_нет      общая фраза  \n",
       "14242  [по дополнительному признаку_нет]  по условиям_нет      общая фраза  \n",
       "14243  [по дополнительному признаку_нет]  по условиям_нет      общая фраза  \n",
       "14244  [по дополнительному признаку_нет]  по условиям_нет      общая фраза  \n",
       "\n",
       "[14245 rows x 5 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FunctionTransformer\n",
    "\n",
    "\n",
    "preprocessor_y = ColumnTransformer(\n",
    "    transformers=[\n",
    "\n",
    "        (\n",
    "            \"onehot\",\n",
    "            OneHotEncoder(sparse_output=False),\n",
    "            onehot_columns,\n",
    "        ),\n",
    "        ('multilabel0', CountVectorizer(analyzer=set), multilabel_columns[0]),\n",
    "        (\"multilabel1\", CountVectorizer(analyzer=set), multilabel_columns[1]),\n",
    "        # (\"vectorizer\", CountVectorizer(), vectorizer_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor_x = ColumnTransformer(transformers=[\n",
    "    ('vectorize', CountVectorizer(), vectorizer_columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class InverseTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, pipe):\n",
    "        self.pipe = pipe\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        inverse_transformers = self.pipe.transformers_\n",
    "\n",
    "        len1 = len(inverse_transformers[0][1].get_feature_names_out())\n",
    "        len2 = len(list(inverse_transformers[1][1].vocabulary_.keys()))\n",
    "\n",
    "        res = inverse_transformers[0][1].inverse_transform([cut[:len1]])\n",
    "        res2 = inverse_transformers[1][1].inverse_transform([cut[len1 : len1 + len2]])\n",
    "        res3 = inverse_transformers[2][1].inverse_transform([cut[len1 + len2 :]])\n",
    "\n",
    "        output = dict(zip(inverse_transformers[0][1].feature_names_in_, res[0]))\n",
    "        output[\"занятость\"] = res2[0].tolist()\n",
    "        output[\"по дополнительному признаку\"] = res3[0].tolist()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inverse_transformers[0][1].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline([\n",
    "#     (\"preprocessor\", preprocessor),\n",
    "#     (\"model\", MLPClassifier(max_iter=400)),\n",
    "#     (\"inverse\", FunctionTransformer())\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prep = preprocessor_y.fit_transform(y)\n",
    "y_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_prep = preprocessor_x.fit_transform(X)\n",
    "# x_prep.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(max_iter=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor_x),\n",
    "    (\"model\", model),\n",
    "    # (\"inverse\", InverseTransformer(preprocessor_y))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'MLPClassifier(max_iter=400)' (type <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[209], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_prep\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Yakov\\Documents\\Projects\\query_classifier\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Yakov\\Documents\\Projects\\query_classifier\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:469\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \n\u001b[0;32m    428\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    468\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m--> 469\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Yakov\\Documents\\Projects\\query_classifier\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:386\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, routed_params)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, routed_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;66;03m# shallow copy of steps - this should really be steps_\u001b[39;00m\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps)\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;66;03m# Setup the memory\u001b[39;00m\n\u001b[0;32m    388\u001b[0m     memory \u001b[38;5;241m=\u001b[39m check_memory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory)\n",
      "File \u001b[1;32mc:\\Users\\Yakov\\Documents\\Projects\\query_classifier\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:256\u001b[0m, in \u001b[0;36mPipeline._validate_steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[0;32m    254\u001b[0m         t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    255\u001b[0m     ):\n\u001b[1;32m--> 256\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    257\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll intermediate steps should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    258\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers and implement fit and transform \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    259\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor be the string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (t, \u001b[38;5;28mtype\u001b[39m(t))\n\u001b[0;32m    261\u001b[0m         )\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We allow last estimator to be None as an identity transformation\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    265\u001b[0m     estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    268\u001b[0m ):\n",
      "\u001b[1;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'MLPClassifier(max_iter=400)' (type <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>) doesn't"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X, y_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_qeury = \"работа грузчиком с проживанием\"\n",
    "query_prep = morphe(example_qeury)\n",
    "\n",
    "frame = pd.DataFrame({'query': [query_prep]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_prep = preprocessor_x.transform(frame)\n",
    "# preds = model.predict(example_prep)\n",
    "preds2 = pipeline.predict(frame)\n",
    "# cut = preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverser = InverseTransformer(preprocessor_y)\n",
    "result = inverser.transform(preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse_transformers = preprocessor_y.transformers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['занятость_нет',\n",
       " 'на неполный день',\n",
       " 'Подработка',\n",
       " 'на дому',\n",
       " 'Вахта',\n",
       " 'Ночная',\n",
       " 'по выходным',\n",
       " 'Удаленная',\n",
       " 'Вечерняя',\n",
       " 'Временная',\n",
       " 'Посменная',\n",
       " 'Дневная',\n",
       " 'Посуточная']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(inverse_transformers[1][1].vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Грузчик', 'с проживанием', 'общие фразы_нет']], dtype=object)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# res = inverse_transformers[0][1].inverse_transform([cut[:303]])\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = dict(zip(inverse_transformers[0][1].feature_names_in_, res[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res2 = inverse_transformers[1][1].inverse_transform([cut[303:316]])\n",
    "# output['занятость'] = res2[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['занятость_нет'], dtype='<U16')]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res3 = inverse_transformers[2][1].inverse_transform([cut[316:]])\n",
    "# output['по дополнительному признаку'] = res3[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'по должности-лемме': 'Грузчик',\n",
       " 'по условиям': 'с проживанием',\n",
       " 'общие фразы': 'общие фразы_нет',\n",
       " 'занятость': ['занятость_нет'],\n",
       " 'по дополнительному признаку': ['по дополнительному признаку_нет']}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill\n",
    "\n",
    "# with open('model.pkl', 'wb') as file:\n",
    "#     dill.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
